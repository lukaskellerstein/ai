import numpy as np
import tensorflow as tf

# ------------------------------------------------------------
# GENERATED BY CHATGPT
# ------------------------------------------------------------


class Perceptron(tf.keras.Model):
    def __init__(self, num_inputs, learning_rate=0.1):
        super().__init__()
        self.num_inputs = num_inputs
        self.learning_rate = learning_rate
        self.dense = tf.keras.layers.Dense(units=1, input_shape=[num_inputs])

    def call(self, inputs):
        return self.dense(inputs)

    def train(self, x, y, epochs=10):

        # stochastic gradient descent (SGD)
        optimizer = tf.optimizers.SGD(learning_rate=self.learning_rate)

        mse_loss = tf.keras.losses.MeanSquaredError()
        for epoch in range(epochs):
            with tf.GradientTape() as tape:
                predictions = self(x)
                loss = mse_loss(y, predictions)
            gradients = tape.gradient(loss, self.trainable_variables)
            optimizer.apply_gradients(zip(gradients, self.trainable_variables))


# ------------------------------------------------------------


# Define training data
x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)
y = np.array([[0], [0], [0], [1]], dtype=np.float32)

# Create and train the perceptron
perceptron = Perceptron(num_inputs=2)
perceptron.train(x, y, epochs=10)

# Test the perceptron on some new data
test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)
predictions = perceptron(test_data)
print(predictions)
